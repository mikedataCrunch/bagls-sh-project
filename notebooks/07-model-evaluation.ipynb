{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aa56c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:13:23.577970Z",
     "start_time": "2022-11-29T12:13:23.556378Z"
    }
   },
   "outputs": [],
   "source": [
    "# dev convenience\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca39c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:13:23.805588Z",
     "start_time": "2022-11-29T12:13:23.579971Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PATHS\n",
    "import config\n",
    "\n",
    "configs = config.nb_configs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "# os.environ[\"WANDB_SILENT\"] = \"True\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"07-model-evaluation.ipynb\"\n",
    "\n",
    "PROJECT_NAME = 'bagls-sh-test' # <=====================\n",
    "RUN_NAME = 'convnet_from_scratch' # <=====================\n",
    "METRICS_TABLE_NAME = 'metrics_table' # <=====================\n",
    "GRADCAM_LAYER_NAME = \"conv2d_3\" # <====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd1d8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:13:26.862798Z",
     "start_time": "2022-11-29T12:13:23.807809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B:  0.13.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiked\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "print(\"W&B: \", wandb.__version__)\n",
    "wandb.login()\n",
    "\n",
    "# # manage logs\n",
    "# import logging\n",
    "\n",
    "# logger = logging.getLogger(\"wandb\")\n",
    "# logger.setLevel(logging.ERROR)\n",
    "\n",
    "# logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a80397d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:13:30.277482Z",
     "start_time": "2022-11-29T12:13:26.868134Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8a189f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:13:31.453976Z",
     "start_time": "2022-11-29T12:13:31.404962Z"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=configs[\"rescale\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "609768c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:32:18.741887Z",
     "start_time": "2022-11-29T12:32:18.229761Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_df(csv_path):\n",
    "    \"\"\"Prepare dataframe for flow_from_dataframe\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['class'] = df[\"is_healthy\"].apply(lambda x : \"healthy\" if x else \"unhealthy\")\n",
    "    df['filename'] = (df[\"Image Id\"].astype(str) + \".png\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2adebc",
   "metadata": {},
   "source": [
    "## Create bootstraps of the `test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14842d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T12:35:13.572218Z",
     "start_time": "2022-11-29T12:35:12.708027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n",
      "Found 3300 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"../test/test\"\n",
    "batch_size = configs[\"batch_size\"]\n",
    "class_names = configs[\"class_names\"]\n",
    "interpol = configs[\"interpol\"]\n",
    "cmap = configs[\"cmap\"]\n",
    "label_mode = configs[\"label_mode\"]\n",
    "labels = configs[\"labels\"]\n",
    "image_size = configs[\"image_size\"]\n",
    "\n",
    "num_bootstrap = 10\n",
    "datasets, labels_list = [], []\n",
    "\n",
    "for i in range(num_bootstrap):\n",
    "    csv_path = os.path.join(PATHS.bootstrap_dir, f\"test-{num_bs}.csv\")\n",
    "    df = prepare_df(csv_path)\n",
    "    labels_list.append(df[\"class\"])\n",
    "    test_dataset = test_datagen.flow_from_dataframe(\n",
    "        df, directory=test_dir, \n",
    "        x_col='filename', y_col='class',\n",
    "        target_size=image_size,\n",
    "        color_mode=cmap,\n",
    "        classes=class_names,\n",
    "        class_mode=label_mode,\n",
    "        batch_size=batch_size,\n",
    "        interpolation=interpol,\n",
    "        validate_filenames=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    datasets.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_name): # <=====================\n",
    "    run = wandb.init(\n",
    "        project=PROJECT_NAME, \n",
    "        group=GROUP_NAME,\n",
    "        name=model_name,\n",
    "        job_type=\"inference-evaluation\", \n",
    "        config=configs, \n",
    "    )\n",
    "    model_at = run.use_artifact(\"model-\" + model_name + \":latest\")\n",
    "    model_dir = model_at.download()\n",
    "    best_model = keras.models.load_model(model_dir)\n",
    "    \n",
    "    metrics_results = best_model.evaluate(test_dataset)\n",
    "    metrics_results = dict(zip([\"loss\"] + list(metrics_dict.keys()), \n",
    "                               metrics_results))\n",
    "    tp, fp, tn, fn = (metrics_results[\"TP\"], metrics_results[\"FP\"], \n",
    "                      metrics_results[\"TN\"], metrics_results[\"FN\"])\n",
    "\n",
    "    add_metrics = {\n",
    "        \"SENSITIVITY\": utils.get_sensitivity(tp, fp, tn, fn),\n",
    "        \"SPECIFICTY\": utils.get_specificity(tp, fp, tn, fn),\n",
    "        \"PPV\": utils.get_ppv(tp, fp, tn, fn),\n",
    "        \"NPV\": utils.get_npv(tp, fp, tn, fn),\n",
    "        \"F1\" : utils.get_fbeta(tp, fp, tn, fn, beta=1),\n",
    "    }\n",
    "    metrics_results.update(add_metrics)\n",
    "\n",
    "    print(f\"Metrics: \\n\", metrics_results)\n",
    "\n",
    "    columns = list(metrics_results.keys())\n",
    "    metrics_table = wandb.Table(columns=columns)\n",
    "    metrics_table.add_data(*metrics_results.values())\n",
    "    wandb.run.log({METRICS_TABLE_NAME : metrics_table})\n",
    "\n",
    "    # add logging of confusion matrix image from matplotlib\n",
    "\n",
    "    # get preds\n",
    "    trained_preds = best_model.predict(test_dataset)\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:msds2022-ml3]",
   "language": "python",
   "name": "conda-env-msds2022-ml3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
