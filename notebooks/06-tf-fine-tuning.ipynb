{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfd5593",
   "metadata": {},
   "source": [
    "# `tensorflow.keras` fine tuning approach\n",
    "\n",
    "This notebook demonstrates a fine-tuning approach. While such an approach was no longer championed in the final models used, it is likely that such may further improve the models performance. \n",
    "\n",
    "The steps in this notebook combined with the tuning of the fine-tuning hyperparameters (e.g., fine-tuning depth) can be done using the demonstrated `sweeps` in this project (shown in another notebook).\n",
    "\n",
    "Notes:\n",
    "1. The fine-tuning step mentioned comes after a transfer learning workflow--that is, using pretrained weights we train a classification head on a new task which may be different from the previous pretraining of the model. Hence, we first train the new classification head on our task (i.e., unhealthy-healthy glottis prediction) while freezing the convolutional base (model with pre-trained weights).\n",
    "\n",
    "2. After an initial training of the dense head (classifier), we unfreeze the convolutional layers with a very low learning rate. Such roughly ensures that preservation of the low level feature maps from pretraining, otherwise--we're almost discarding the pretrained weights the earlier convolutional layers. Usually, our goal is to fine tune the weights that result to the forming of high level feature maps (i.e., concepts--for example, the glottis shape).\n",
    "\n",
    "Given the notes, the first few steps are just similar to that of the transfer learning notebooks presented in this repository.\n",
    "\n",
    "References:\n",
    "\n",
    "* The pretrained weights published by [Mei et al (2022)](https://pubs.rsna.org/doi/10.1148/ryai.210315) in their github [link](https://github.com/BMEII-AI/RadImageNet).\n",
    "\n",
    "* The preprocessing pipeline by the BAGLS team contained in this github [link](https://github.com/anki-xyz/bagls/blob/master/Utils/DataGenerator.py#L109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760317d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:44.217740Z",
     "start_time": "2022-11-27T16:49:44.193750Z"
    }
   },
   "outputs": [],
   "source": [
    "# dev convenience\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a72fdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:44.439374Z",
     "start_time": "2022-11-27T16:49:44.220579Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import PATHS\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c55ee0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:46.750606Z",
     "start_time": "2022-11-27T16:49:44.442433Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf loader\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5fa101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:47.804012Z",
     "start_time": "2022-11-27T16:49:46.753996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17548735796084712585\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10925703168\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1219952536450970898\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:49:46.797918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 16:49:47.789387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 10419 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e823b74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:47.861633Z",
     "start_time": "2022-11-27T16:49:47.808256Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1013d50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:47.914062Z",
     "start_time": "2022-11-27T16:49:47.864307Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# initialize data generator\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.05,\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=10,\n",
    ")\n",
    "\n",
    "validation_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=1./255,\n",
    "    validation_split=0.05,\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe53015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:50.901342Z",
     "start_time": "2022-11-27T16:49:47.916537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52393 images belonging to 2 classes.\n",
      "Found 2757 images belonging to 2 classes.\n",
      "Found 3300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# source directories\n",
    "# train_dir = '../sample-dataset/train'\n",
    "# test_dir = '../sample-dataset/test'\n",
    "\n",
    "train_dir = '../dataset/train'\n",
    "test_dir = '../dataset/test'\n",
    "\n",
    "batch_size = 64\n",
    "class_names = [\"healthy\", \"unhealthy\"]\n",
    "interpol = \"bilinear\"\n",
    "cmap = \"rgb\"\n",
    "label_mode = \"categorical\" # \n",
    "labels = \"inferred\"\n",
    "image_size = (224, 224)\n",
    "\n",
    "\n",
    "train_dataset = train_data_generator.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode=cmap,\n",
    "    classes=class_names,\n",
    "    class_mode=label_mode,\n",
    "    batch_size=batch_size,\n",
    "    interpolation=interpol,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_dataset = train_data_generator.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode=cmap,\n",
    "    classes=class_names,\n",
    "    class_mode=label_mode,\n",
    "    batch_size=batch_size,\n",
    "    interpolation=interpol,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "test_dataset = test_data_generator.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode=cmap,\n",
    "    classes=class_names,\n",
    "    class_mode=label_mode,\n",
    "    batch_size=batch_size,\n",
    "    interpolation=interpol,\n",
    "    shuffle=False, # do not shuffle for later evaluation, alphanum sort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fb3ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:50.971813Z",
     "start_time": "2022-11-27T16:49:50.904693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "def define_model(pretrained):\n",
    "    conv_base = pretrained(\n",
    "        include_top=False,\n",
    "        weights=PATHS.resnet50_weights,\n",
    "        input_shape=(*image_size, 3),\n",
    "        pooling='avg',\n",
    "    )\n",
    "    print(\"Num trainable at load:\", len(conv_base.trainable_weights)) \n",
    "    conv_base.trainable = False\n",
    "    print(\"Num trainable:\", len(conv_base.trainable_weights)) \n",
    "    \n",
    "    x = conv_base.output\n",
    "    \n",
    "    # layers at this stage are arbitrary\n",
    "    # can be subjected to hyperparam tuning\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = keras.layers.Dense(units=512, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # multiclass\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=conv_base.input, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efb0824e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.069580Z",
     "start_time": "2022-11-27T16:49:50.974026Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:49:51.046438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10419 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num trainable at load: 212\n",
      "Num trainable: 0\n"
     ]
    }
   ],
   "source": [
    "pretrained = keras.applications.ResNet50\n",
    "model = define_model(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf6483d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.126018Z",
     "start_time": "2022-11-27T16:49:53.076813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note on batchnorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e8eb82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.179666Z",
     "start_time": "2022-11-27T16:49:53.128681Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_layer_trainable(conv_model, only_true=False):\n",
    "    \"\"\"Inspect trainable layers\"\"\"\n",
    "    for layer in conv_model.layers:\n",
    "        if only_true & layer.trainable:\n",
    "            if layer.trainable:\n",
    "                print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n",
    "        else:\n",
    "            print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104d1c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.258306Z",
     "start_time": "2022-11-27T16:49:53.183553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False:\tinput_1\n",
      "False:\tconv1_pad\n",
      "False:\tconv1_conv\n",
      "False:\tconv1_bn\n",
      "False:\tconv1_relu\n",
      "False:\tpool1_pad\n",
      "False:\tpool1_pool\n",
      "False:\tconv2_block1_1_conv\n",
      "False:\tconv2_block1_1_bn\n",
      "False:\tconv2_block1_1_relu\n",
      "False:\tconv2_block1_2_conv\n",
      "False:\tconv2_block1_2_bn\n",
      "False:\tconv2_block1_2_relu\n",
      "False:\tconv2_block1_0_conv\n",
      "False:\tconv2_block1_3_conv\n",
      "False:\tconv2_block1_0_bn\n",
      "False:\tconv2_block1_3_bn\n",
      "False:\tconv2_block1_add\n",
      "False:\tconv2_block1_out\n",
      "False:\tconv2_block2_1_conv\n",
      "False:\tconv2_block2_1_bn\n",
      "False:\tconv2_block2_1_relu\n",
      "False:\tconv2_block2_2_conv\n",
      "False:\tconv2_block2_2_bn\n",
      "False:\tconv2_block2_2_relu\n",
      "False:\tconv2_block2_3_conv\n",
      "False:\tconv2_block2_3_bn\n",
      "False:\tconv2_block2_add\n",
      "False:\tconv2_block2_out\n",
      "False:\tconv2_block3_1_conv\n",
      "False:\tconv2_block3_1_bn\n",
      "False:\tconv2_block3_1_relu\n",
      "False:\tconv2_block3_2_conv\n",
      "False:\tconv2_block3_2_bn\n",
      "False:\tconv2_block3_2_relu\n",
      "False:\tconv2_block3_3_conv\n",
      "False:\tconv2_block3_3_bn\n",
      "False:\tconv2_block3_add\n",
      "False:\tconv2_block3_out\n",
      "False:\tconv3_block1_1_conv\n",
      "False:\tconv3_block1_1_bn\n",
      "False:\tconv3_block1_1_relu\n",
      "False:\tconv3_block1_2_conv\n",
      "False:\tconv3_block1_2_bn\n",
      "False:\tconv3_block1_2_relu\n",
      "False:\tconv3_block1_0_conv\n",
      "False:\tconv3_block1_3_conv\n",
      "False:\tconv3_block1_0_bn\n",
      "False:\tconv3_block1_3_bn\n",
      "False:\tconv3_block1_add\n",
      "False:\tconv3_block1_out\n",
      "False:\tconv3_block2_1_conv\n",
      "False:\tconv3_block2_1_bn\n",
      "False:\tconv3_block2_1_relu\n",
      "False:\tconv3_block2_2_conv\n",
      "False:\tconv3_block2_2_bn\n",
      "False:\tconv3_block2_2_relu\n",
      "False:\tconv3_block2_3_conv\n",
      "False:\tconv3_block2_3_bn\n",
      "False:\tconv3_block2_add\n",
      "False:\tconv3_block2_out\n",
      "False:\tconv3_block3_1_conv\n",
      "False:\tconv3_block3_1_bn\n",
      "False:\tconv3_block3_1_relu\n",
      "False:\tconv3_block3_2_conv\n",
      "False:\tconv3_block3_2_bn\n",
      "False:\tconv3_block3_2_relu\n",
      "False:\tconv3_block3_3_conv\n",
      "False:\tconv3_block3_3_bn\n",
      "False:\tconv3_block3_add\n",
      "False:\tconv3_block3_out\n",
      "False:\tconv3_block4_1_conv\n",
      "False:\tconv3_block4_1_bn\n",
      "False:\tconv3_block4_1_relu\n",
      "False:\tconv3_block4_2_conv\n",
      "False:\tconv3_block4_2_bn\n",
      "False:\tconv3_block4_2_relu\n",
      "False:\tconv3_block4_3_conv\n",
      "False:\tconv3_block4_3_bn\n",
      "False:\tconv3_block4_add\n",
      "False:\tconv3_block4_out\n",
      "False:\tconv4_block1_1_conv\n",
      "False:\tconv4_block1_1_bn\n",
      "False:\tconv4_block1_1_relu\n",
      "False:\tconv4_block1_2_conv\n",
      "False:\tconv4_block1_2_bn\n",
      "False:\tconv4_block1_2_relu\n",
      "False:\tconv4_block1_0_conv\n",
      "False:\tconv4_block1_3_conv\n",
      "False:\tconv4_block1_0_bn\n",
      "False:\tconv4_block1_3_bn\n",
      "False:\tconv4_block1_add\n",
      "False:\tconv4_block1_out\n",
      "False:\tconv4_block2_1_conv\n",
      "False:\tconv4_block2_1_bn\n",
      "False:\tconv4_block2_1_relu\n",
      "False:\tconv4_block2_2_conv\n",
      "False:\tconv4_block2_2_bn\n",
      "False:\tconv4_block2_2_relu\n",
      "False:\tconv4_block2_3_conv\n",
      "False:\tconv4_block2_3_bn\n",
      "False:\tconv4_block2_add\n",
      "False:\tconv4_block2_out\n",
      "False:\tconv4_block3_1_conv\n",
      "False:\tconv4_block3_1_bn\n",
      "False:\tconv4_block3_1_relu\n",
      "False:\tconv4_block3_2_conv\n",
      "False:\tconv4_block3_2_bn\n",
      "False:\tconv4_block3_2_relu\n",
      "False:\tconv4_block3_3_conv\n",
      "False:\tconv4_block3_3_bn\n",
      "False:\tconv4_block3_add\n",
      "False:\tconv4_block3_out\n",
      "False:\tconv4_block4_1_conv\n",
      "False:\tconv4_block4_1_bn\n",
      "False:\tconv4_block4_1_relu\n",
      "False:\tconv4_block4_2_conv\n",
      "False:\tconv4_block4_2_bn\n",
      "False:\tconv4_block4_2_relu\n",
      "False:\tconv4_block4_3_conv\n",
      "False:\tconv4_block4_3_bn\n",
      "False:\tconv4_block4_add\n",
      "False:\tconv4_block4_out\n",
      "False:\tconv4_block5_1_conv\n",
      "False:\tconv4_block5_1_bn\n",
      "False:\tconv4_block5_1_relu\n",
      "False:\tconv4_block5_2_conv\n",
      "False:\tconv4_block5_2_bn\n",
      "False:\tconv4_block5_2_relu\n",
      "False:\tconv4_block5_3_conv\n",
      "False:\tconv4_block5_3_bn\n",
      "False:\tconv4_block5_add\n",
      "False:\tconv4_block5_out\n",
      "False:\tconv4_block6_1_conv\n",
      "False:\tconv4_block6_1_bn\n",
      "False:\tconv4_block6_1_relu\n",
      "False:\tconv4_block6_2_conv\n",
      "False:\tconv4_block6_2_bn\n",
      "False:\tconv4_block6_2_relu\n",
      "False:\tconv4_block6_3_conv\n",
      "False:\tconv4_block6_3_bn\n",
      "False:\tconv4_block6_add\n",
      "False:\tconv4_block6_out\n",
      "False:\tconv5_block1_1_conv\n",
      "False:\tconv5_block1_1_bn\n",
      "False:\tconv5_block1_1_relu\n",
      "False:\tconv5_block1_2_conv\n",
      "False:\tconv5_block1_2_bn\n",
      "False:\tconv5_block1_2_relu\n",
      "False:\tconv5_block1_0_conv\n",
      "False:\tconv5_block1_3_conv\n",
      "False:\tconv5_block1_0_bn\n",
      "False:\tconv5_block1_3_bn\n",
      "False:\tconv5_block1_add\n",
      "False:\tconv5_block1_out\n",
      "False:\tconv5_block2_1_conv\n",
      "False:\tconv5_block2_1_bn\n",
      "False:\tconv5_block2_1_relu\n",
      "False:\tconv5_block2_2_conv\n",
      "False:\tconv5_block2_2_bn\n",
      "False:\tconv5_block2_2_relu\n",
      "False:\tconv5_block2_3_conv\n",
      "False:\tconv5_block2_3_bn\n",
      "False:\tconv5_block2_add\n",
      "False:\tconv5_block2_out\n",
      "False:\tconv5_block3_1_conv\n",
      "False:\tconv5_block3_1_bn\n",
      "False:\tconv5_block3_1_relu\n",
      "False:\tconv5_block3_2_conv\n",
      "False:\tconv5_block3_2_bn\n",
      "False:\tconv5_block3_2_relu\n",
      "False:\tconv5_block3_3_conv\n",
      "False:\tconv5_block3_3_bn\n",
      "False:\tconv5_block3_add\n",
      "False:\tconv5_block3_out\n",
      "False:\tavg_pool\n",
      "True:\tflatten\n",
      "True:\tdropout\n",
      "True:\tdense\n",
      "True:\tdropout_1\n",
      "True:\tdense_1\n"
     ]
    }
   ],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019baf4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.323382Z",
     "start_time": "2022-11-27T16:49:53.260687Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "thresh = 0.5\n",
    "metrics_dict = {\n",
    "    \"ACC\":  metrics.BinaryAccuracy(name=\"ACC\", threshold=thresh),\n",
    "    \"AUC-ROC\": metrics.AUC(name='ROC', curve='ROC'),\n",
    "    \"AUC-PR\": metrics.AUC(name='PR', curve='PR'),\n",
    "    \"TP\": metrics.TruePositives(name=\"TP\", thresholds=thresh),\n",
    "    \"TN\": metrics.TrueNegatives(name=\"TN\", thresholds=thresh),\n",
    "    \"FP\": metrics.FalsePositives(name=\"FP\", thresholds=thresh),\n",
    "    \"FN\": metrics.FalseNegatives(name=\"FN\", thresholds=thresh),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc52a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:49:53.382641Z",
     "start_time": "2022-11-27T16:49:53.325938Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# opt = optimizers.Adam(learning_rate=1e-06)\n",
    "opt = optimizers.Adam()\n",
    "met = list(metrics_dict.values())\n",
    "\n",
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(), # multiclass\n",
    "    optimizer=opt,\n",
    "    metrics=met,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce3ba6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T16:50:21.453332Z",
     "start_time": "2022-11-27T16:49:53.385119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:49:54.277314: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-27 16:49:56.926646: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45578143, 0.5442186 ],\n",
       "       [0.47979867, 0.5202014 ],\n",
       "       [0.46865255, 0.5313474 ],\n",
       "       ...,\n",
       "       [0.46448022, 0.5355198 ],\n",
       "       [0.47043678, 0.5295632 ],\n",
       "       [0.5413459 , 0.45865414]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify arch\n",
    "# base predictions with untrained classif head\n",
    "base_preds = model.predict(test_dataset)\n",
    "base_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6124b283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.382393Z",
     "start_time": "2022-11-27T16:50:21.458427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "819/819 [==============================] - 1017s 1s/step - loss: 0.4471 - ACC: 0.7847 - ROC: 0.8706 - PR: 0.8729 - TP: 41114.0000 - TN: 41114.0000 - FP: 11279.0000 - FN: 11279.0000 - val_loss: 0.2978 - val_ACC: 0.8796 - val_ROC: 0.9564 - val_PR: 0.9580 - val_TP: 2425.0000 - val_TN: 2425.0000 - val_FP: 332.0000 - val_FN: 332.0000\n",
      "Epoch 2/20\n",
      "548/819 [===================>..........] - ETA: 5:06 - loss: 0.2834 - ACC: 0.8773 - ROC: 0.9529 - PR: 0.9543 - TP: 30750.0000 - TN: 30750.0000 - FP: 4299.0000 - FN: 4299.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2245/389918832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# no save callback, not yet done training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# less epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda-envs/msds2022-ml3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no save callback, not yet done training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20, # less epochs\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890a301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.386701Z",
     "start_time": "2022-11-27T17:17:42.386645Z"
    }
   },
   "outputs": [],
   "source": [
    "# set base layers to trainable  \n",
    "def set_trainable_base(model):\n",
    "    \"\"\"Specific for resnet50v2 where there are preact_bns and otherwise\"\"\"\n",
    "    for layer in model.layers[:]:          \n",
    "        if ('preact_bn' in layer.name):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e65303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.389294Z",
     "start_time": "2022-11-27T17:17:42.389268Z"
    }
   },
   "outputs": [],
   "source": [
    "# make other layers trainable\n",
    "model = set_trainable_base(model)\n",
    "print_layer_trainable(model) # verify that all is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76204e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.391663Z",
     "start_time": "2022-11-27T17:17:42.391639Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=1e-06) # use small LR\n",
    "met = list(metrics_dict.values())\n",
    "\n",
    "model.compile(\n",
    "    loss=losses.CategoricalCrossentropy(), # multiclass\n",
    "    optimizer=opt,\n",
    "    metrics=met,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01311215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.393560Z",
     "start_time": "2022-11-27T17:17:42.393537Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_save_path(model_name):\n",
    "    model_dir = PATHS.models_dir\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_name)\n",
    "    return model_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb28d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.396438Z",
     "start_time": "2022-11-27T17:17:42.396414Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"resnet_ft_radimagenet_weights.keras\"\n",
    "model_filepath = get_save_path(model_name)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_filepath,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_ROC\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# set verbose to 0 to limit notebook size\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=30, # more epochs\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54745d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.398122Z",
     "start_time": "2022-11-27T17:17:42.398100Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model again and inspect which layers are trainable\n",
    "best_model = keras.models.load_model(model_filepath)\n",
    "print_layer_trainable(model)\n",
    "for layer in model.layers[:]:          \n",
    "    layer.trainable = False\n",
    "print_layer_trainable(model)\n",
    "\n",
    "# save after editing trainable layers\n",
    "best_model.save(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ae58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T17:17:42.400290Z",
     "start_time": "2022-11-27T17:17:42.400272Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(model_filepath)\n",
    "\n",
    "# test metrics\n",
    "metrics_results = best_model.evaluate(test_dataset)\n",
    "print(f\"Metrics: \\n\", dict(zip(metrics_results, metrics_dict)))\n",
    "\n",
    "# get preds\n",
    "trained_preds = best_model.predict(test_dataset)\n",
    "trained_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b21018",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:msds2022-ml3]",
   "language": "python",
   "name": "conda-env-msds2022-ml3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
